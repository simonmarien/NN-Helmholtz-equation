{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Helmholtz Boundary data","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.special import jv\n\n# Define the parameters of the problem\nk = 20  # wavenumber\nxi = 1  # xi\n\n# Define the Lipschitz domain\nx = np.linspace(0, 1, 501)\ny = np.linspace(-0.5, 0.5, 501)\nX, Y = np.meshgrid(x, y)\n\ndef cart2pol(x, y):\n    R = np.sqrt(x**2 + y**2)\n    phi = np.arctan2(y, x)\n    return(R, phi)\n\ndef analytical_solution(x, y, k, order=1):\n  (r,theta) = cart2pol(x,y)\n  u_star = jv(order, k * r) * np.exp(1j * order * theta)\n  return u_star\n\nR,THETA = cart2pol(X,Y)\n\n# Compute the solution\nU = jv(xi, k * R) * np.exp(1j * xi * THETA)\n# U = analytical_solution(X,Y,k)\n# Plot the solution\nfig, ax = plt.subplots(figsize=(8, 4))\nim = ax.imshow(np.real(U), extent=[0, 1, -0.5, 0.5], cmap='viridis')\nfig.colorbar(im)\nax.set_title('Analytical Solution of Circular Waves')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-20T11:19:34.987513Z","iopub.execute_input":"2023-04-20T11:19:34.987902Z","iopub.status.idle":"2023-04-20T11:19:35.588023Z","shell.execute_reply.started":"2023-04-20T11:19:34.987870Z","shell.execute_reply":"2023-04-20T11:19:35.586774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_training_data(Nf, Ng, x_min, x_max, y_min, y_max):\n    # Create random training points in the domain\n    Xf = torch.rand(Nf, 2)  # Randomly sample Nf points\n    Xf[:, 0] = Xf[:, 0] * (x_max - x_min) + x_min\n    Xf[:, 1] = Xf[:, 1] * (y_max - y_min) + y_min\n    Xf.requires_grad = True\n\n    # Create uniform boundary points\n    Xg = []\n    x_boundary = np.linspace(x_min, x_max, Ng)\n    y_boundary = np.linspace(y_min, y_max, Ng)\n\n    for x in x_boundary:\n        Xg.append([x, y_min])\n        Xg.append([x, y_max])\n\n    for y in y_boundary[1:-1]:\n        Xg.append([x_min, y])\n        Xg.append([x_max, y])\n\n    Xg = torch.tensor(Xg, dtype=torch.float32)\n    Xg.requires_grad = True\n\n    return Xf, Xg\n","metadata":{"execution":{"iopub.status.busy":"2023-04-20T11:19:35.590188Z","iopub.execute_input":"2023-04-20T11:19:35.590566Z","iopub.status.idle":"2023-04-20T11:19:35.601540Z","shell.execute_reply.started":"2023-04-20T11:19:35.590529Z","shell.execute_reply":"2023-04-20T11:19:35.600016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def loss_function(tann, Xf, Xg, k, analytical_solution):\n    # Evaluate the model on the training and boundary points\n    u_f = tann(Xf)\n    u_g = tann(Xg)\n\n    # Calculate the Helmholtz equation residuals\n    u_f_x = torch.autograd.grad(u_f, Xf, torch.ones_like(u_f), create_graph=True, retain_graph=True, only_inputs=True)[0]\n    u_f_xx = torch.autograd.grad(u_f_x[:, 0], Xf, torch.ones_like(u_f_x[:, 0]), create_graph=True, retain_graph=True, only_inputs=True)[0][:, 0]\n    u_f_yy = torch.autograd.grad(u_f_x[:, 1], Xf, torch.ones_like(u_f_x[:, 1]), create_graph=True, retain_graph=True, only_inputs=True)[0][:, 1]\n\n    laplacian_u = u_f_xx + u_f_yy\n    equation_residuals = laplacian_u + k**2 * u_f.view(-1)\n\n    # Calculate boundary condition residuals\n    Xg_np = Xg.detach().numpy()\n    g = analytical_solution(Xg_np[:, 0], Xg_np[:, 1], k)\n    g = torch.tensor(np.real(g), dtype=torch.float32).view(-1, 1)\n\n    boundary_residuals = u_g - g\n\n    # Combine residuals and return the total loss\n    loss = torch.mean(equation_residuals**2) + torch.mean(boundary_residuals**2)\n    return loss","metadata":{"execution":{"iopub.status.busy":"2023-04-20T11:19:35.603555Z","iopub.execute_input":"2023-04-20T11:19:35.604420Z","iopub.status.idle":"2023-04-20T11:19:35.620377Z","shell.execute_reply.started":"2023-04-20T11:19:35.604229Z","shell.execute_reply":"2023-04-20T11:19:35.619252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TANN Model","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim","metadata":{"execution":{"iopub.status.busy":"2023-04-20T11:19:35.621868Z","iopub.execute_input":"2023-04-20T11:19:35.622742Z","iopub.status.idle":"2023-04-20T11:19:35.635558Z","shell.execute_reply.started":"2023-04-20T11:19:35.622693Z","shell.execute_reply":"2023-04-20T11:19:35.634438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TANN(nn.Module):\n    def __init__(self, input_size, hidden_units, output_size, hidden_layers):\n        super(TANN, self).__init__()\n        self.input_size = input_size\n        self.hidden_units = hidden_units\n        self.output_size = output_size\n        self.hidden_layers = hidden_layers\n\n        layers = []\n        layers.append(nn.Linear(self.input_size, self.hidden_units))\n        layers.append(nn.Tanh())\n\n        for _ in range(self.hidden_layers - 1):\n            layers.append(nn.Linear(self.hidden_units, self.hidden_units))\n            layers.append(nn.Tanh())\n\n        layers.append(nn.Linear(self.hidden_units, self.output_size))\n\n        self.model = nn.Sequential(*layers)\n\n    def forward(self, x):\n        return self.model(x)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T11:19:35.638635Z","iopub.execute_input":"2023-04-20T11:19:35.639157Z","iopub.status.idle":"2023-04-20T11:19:35.650360Z","shell.execute_reply.started":"2023-04-20T11:19:35.639120Z","shell.execute_reply":"2023-04-20T11:19:35.649012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_tann(tann, Xf, Xg, k, analytical_solution, epochs=50000, lr=1e-3, stop_criterion=2e-16):\n    optimizer = optim.LBFGS(tann.parameters(), lr=lr, max_iter=50)\n\n    for epoch in range(epochs):\n        def closure():\n            optimizer.zero_grad()\n            loss = loss_function(tann, Xf, Xg, k, analytical_solution)\n            loss.backward()\n            return loss\n\n        optimizer.step(closure)\n\n        # Check stopping criterion\n        gradients = torch.cat([param.grad.view(-1) for param in tann.parameters()])\n        max_gradient = torch.max(torch.abs(gradients)).item()\n        if max_gradient < stop_criterion:\n            break\n        \n#         if epoch % 1000 == 0:\n#             loss = loss_function(tann, Xf, Xg, k, analytical_solution)\n#             print(\"Epoch:\", epoch, \"Loss:\", loss.item())\n\n    return tann\n","metadata":{"execution":{"iopub.status.busy":"2023-04-20T11:19:35.651790Z","iopub.execute_input":"2023-04-20T11:19:35.652172Z","iopub.status.idle":"2023-04-20T11:19:35.666560Z","shell.execute_reply.started":"2023-04-20T11:19:35.652120Z","shell.execute_reply":"2023-04-20T11:19:35.665465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SIREN Model","metadata":{}},{"cell_type":"code","source":"class SIREN(nn.Module):\n    def __init__(self, input_size, hidden_units, output_size, hidden_layers):\n        super(SIREN, self).__init__()\n        self.input_size = input_size\n        self.hidden_units = hidden_units\n        self.output_size = output_size\n        self.hidden_layers = hidden_layers\n\n        layers = []\n        layers.append(nn.Linear(self.input_size, self.hidden_units))\n        layers.append(nn.SiLU()) # Sin activation\n\n        for _ in range(self.hidden_layers - 1):\n            layers.append(nn.Linear(self.hidden_units, self.hidden_units))\n            layers.append(nn.SiLU())\n\n        layers.append(nn.Linear(self.hidden_units, self.output_size))\n\n        self.model = nn.Sequential(*layers)\n\n    def forward(self, x):\n        return self.model(x)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T11:19:35.667979Z","iopub.execute_input":"2023-04-20T11:19:35.668384Z","iopub.status.idle":"2023-04-20T11:19:35.679329Z","shell.execute_reply.started":"2023-04-20T11:19:35.668341Z","shell.execute_reply":"2023-04-20T11:19:35.678513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_siren(siren, Xf, Xg, k, analytical_solution, epochs=50000, lr=1e-3, stop_criterion=2e-16):\n    optimizer = optim.LBFGS(siren.parameters(), lr=lr, max_iter=50)\n\n    for epoch in range(epochs):\n        def closure():\n            optimizer.zero_grad()\n            loss = loss_function(siren, Xf, Xg, k, analytical_solution)\n            loss.backward()\n            return loss\n\n        optimizer.step(closure)\n\n        # Check stopping criterion\n        gradients = torch.cat([param.grad.view(-1) for param in siren.parameters()])\n        max_gradient = torch.max(torch.abs(gradients)).item()\n        if max_gradient < stop_criterion:\n            break\n        \n#         if epoch % 1000 == 0:\n#             loss = loss_function(tann, Xf, Xg, k, analytical_solution)\n#             print(\"Epoch:\", epoch, \"Loss:\", loss.item())\n\n    return siren\n","metadata":{"execution":{"iopub.status.busy":"2023-04-20T11:19:35.680237Z","iopub.execute_input":"2023-04-20T11:19:35.680530Z","iopub.status.idle":"2023-04-20T11:19:35.699918Z","shell.execute_reply.started":"2023-04-20T11:19:35.680501Z","shell.execute_reply":"2023-04-20T11:19:35.698317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## PWNN","metadata":{}},{"cell_type":"code","source":"#Custom activation function\nclass ExpI(nn.Module):\n    def forward(self, x):\n#         x_real = x[:, 0]\n#         x_imag = x[:, 1]\n#         y_real = torch.exp(x_real) * torch.cos(x_imag)\n#         y_imag = torch.exp(x_real) * torch.sin(x_imag)\n#         y = torch.cat((y_real, y_imag), dim=1)\n        y = torch.exp(x)\n        return y","metadata":{"execution":{"iopub.status.busy":"2023-04-20T11:19:35.701329Z","iopub.execute_input":"2023-04-20T11:19:35.701650Z","iopub.status.idle":"2023-04-20T11:19:35.712845Z","shell.execute_reply.started":"2023-04-20T11:19:35.701618Z","shell.execute_reply":"2023-04-20T11:19:35.711328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PWNN(nn.Module):\n    def __init__(self, input_size, hidden_units, output_size, hidden_layers):\n        super(PWNN, self).__init__()\n        self.input_size = input_size\n        self.hidden_units = hidden_units\n        self.output_size = output_size\n        self.hidden_layers = hidden_layers\n\n        layers = []\n        layers.append(nn.Linear(self.input_size, self.hidden_units))\n        layers.append(ExpI()) # Real part activation function\n        layers.append(nn.Linear(self.hidden_units, self.hidden_units))\n        layers.append(ExpI()) # Real part activation function\n\n        for _ in range(self.hidden_layers - 1):\n            layers.append(nn.Linear(self.hidden_units, self.hidden_units))\n            layers.append(ExpI()) # Real part activation function\n\n        layers.append(nn.Linear(self.hidden_units, self.output_size))\n\n        self.model = nn.Sequential(*layers)\n\n    def forward(self, x):\n        y = self.model(x)\n\n        return y","metadata":{"execution":{"iopub.status.busy":"2023-04-20T11:19:35.713887Z","iopub.execute_input":"2023-04-20T11:19:35.714238Z","iopub.status.idle":"2023-04-20T11:19:35.726670Z","shell.execute_reply.started":"2023-04-20T11:19:35.714203Z","shell.execute_reply":"2023-04-20T11:19:35.725371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_pwnn(pwnn, Xf, Xg, k, analytical_solution, epochs=50000, lr=1e-3, stop_criterion=2e-16):\n    optimizer = optim.LBFGS(pwnn.parameters(), lr=lr, max_iter=50)\n\n    for epoch in range(epochs):\n        def closure():\n            optimizer.zero_grad()\n            loss = loss_function_pwnn(pwnn, Xf, Xg, k, analytical_solution)\n            loss.backward()\n            return loss\n\n        optimizer.step(closure)\n\n        # Check stopping criterion\n        gradients = torch.cat([param.grad.view(-1) for param in pwnn.parameters()])\n        max_gradient = torch.max(torch.abs(gradients)).item()\n        if max_gradient < stop_criterion:\n            break\n        \n#         if epoch % 1000 == 0:\n#             loss = loss_function_pwnn(pwnn, Xf, Xg, k, analytical_solution)\n#             print(\"Epoch:\", epoch, \"Loss:\", loss.item())\n\n    return pwnn","metadata":{"execution":{"iopub.status.busy":"2023-04-20T11:19:35.728592Z","iopub.execute_input":"2023-04-20T11:19:35.729072Z","iopub.status.idle":"2023-04-20T11:19:35.742981Z","shell.execute_reply.started":"2023-04-20T11:19:35.729017Z","shell.execute_reply":"2023-04-20T11:19:35.742032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Experiments","metadata":{}},{"cell_type":"code","source":"def create_test_data(N_test, x_min, x_max, y_min, y_max):\n    X_test = np.linspace(x_min, x_max, int(np.sqrt(N_test)))\n    Y_test = np.linspace(y_min, y_max, int(np.sqrt(N_test)))\n    X_test, Y_test = np.meshgrid(X_test, Y_test)\n    X_test = X_test.flatten()\n    Y_test = Y_test.flatten()\n    X_test = np.column_stack((X_test, Y_test))\n    X_test = torch.tensor(X_test, dtype=torch.float32)\n    return X_test\n\ndef calculate_accuracy(trained_tann, X_test, k, analytical_solution):\n    with torch.no_grad():\n        X_test.requires_grad = True\n        u_pred = trained_tann(X_test)\n        print(type(u_pred))\n        u_exact = analytical_solution(X_test[:, 0].numpy(), X_test[:, 1].numpy(), k)\n        u_exact = np.real(u_exact)\n        u_exact = torch.tensor(u_exact, dtype=torch.float32).view(-1, 1)\n        error = torch.norm(np.abs(u_exact) - np.abs(u_pred), dim=0) / torch.norm(np.abs(u_exact), dim=0)\n        accuracy = -torch.log10(error)\n        if(accuracy<0):\n            print(\"error:\",error,\"acc:\", accuracy)\n        return accuracy.item()","metadata":{"execution":{"iopub.status.busy":"2023-04-20T11:19:35.744241Z","iopub.execute_input":"2023-04-20T11:19:35.744616Z","iopub.status.idle":"2023-04-20T11:19:35.757064Z","shell.execute_reply.started":"2023-04-20T11:19:35.744581Z","shell.execute_reply":"2023-04-20T11:19:35.755992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Parameters\nk = 20\nNg = 5*k*4\nNf = 5*(k**2)\nLayers = [1,2,3,4]\nUnits = [k,2*k,4*k]\n\nx_min,x_max,y_min,y_max = 0,1,-0.5,0.5\nepochs = 2000\nlr= 1e-3\ninput_size = 2\noutput_size = 1\nN_test = 10000","metadata":{"execution":{"iopub.status.busy":"2023-04-20T11:19:35.758281Z","iopub.execute_input":"2023-04-20T11:19:35.758612Z","iopub.status.idle":"2023-04-20T11:19:35.772526Z","shell.execute_reply.started":"2023-04-20T11:19:35.758580Z","shell.execute_reply":"2023-04-20T11:19:35.771470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\nprint(\"Pwnn model with\", Layers, Units)\nfor layer in Layers:\n    for unit in Units:\n        # Create training data\n        Xf,Xg = create_training_data(Nf, Ng, x_min, x_max, y_min, y_max)\n        print(Xf[0])\n        # Create Model\n        # model = TANN(input_size, unit, output_size, layer)\n        # model = SIREN(input_size, unit, output_size, layer)\n        model = PWNN(input_size, unit, output_size, layer)\n        trained_model = train_tann(model, Xf, Xg, k, analytical_solution, epochs=epochs, lr=lr)\n        # Create Test Data\n        X_test = create_test_data(N_test, x_min, x_max, y_min, y_max)\n        accuracy = calculate_accuracy(trained_model, X_test, k, analytical_solution)\n        print(\"Layers:\",layer,\"Units:\",unit,\"Accuracy: \", accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T11:19:35.775561Z","iopub.execute_input":"2023-04-20T11:19:35.775922Z","iopub.status.idle":"2023-04-20T11:20:10.932078Z","shell.execute_reply.started":"2023-04-20T11:19:35.775884Z","shell.execute_reply":"2023-04-20T11:20:10.931225Z"},"trusted":true},"execution_count":null,"outputs":[]}]}